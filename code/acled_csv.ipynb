{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5e010b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /opt/conda/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data_id  iso event_id_cnty  event_id_no_cnty   event_date  year  \\\n",
      "0  7118851  356      IND74745             74745  30 May 2020  2020   \n",
      "1  7118861  356      IND74746             74746  30 May 2020  2020   \n",
      "2  7118864  356      IND74748             74748  30 May 2020  2020   \n",
      "3  7118903  356      IND74739             74739  30 May 2020  2020   \n",
      "4  7118904  356      IND74740             74740  30 May 2020  2020   \n",
      "\n",
      "   time_precision event_type         sub_event_type              actor1  ...  \\\n",
      "0               1      Riots  Violent demonstration     Rioters (India)  ...   \n",
      "1               1   Protests       Peaceful protest  Protesters (India)  ...   \n",
      "2               1   Protests       Peaceful protest  Protesters (India)  ...   \n",
      "3               1      Riots           Mob violence     Rioters (India)  ...   \n",
      "4               1      Riots  Violent demonstration     Rioters (India)  ...   \n",
      "\n",
      "    location   latitude  longitude geo_precision          source  \\\n",
      "0   Uluberia  22.475599  88.098900             1       The Hindu   \n",
      "1    Jamuria  23.704599  87.078697             1       The Hindu   \n",
      "2       Suri  23.908001  87.527702             1       The Hindu   \n",
      "3  Halisahar  22.944000  88.418999             1  Times of India   \n",
      "4  Baranagar  22.646700  88.373596             1  Times of India   \n",
      "\n",
      "   source_scale                                              notes fatalities  \\\n",
      "0      National  On 30 May 2020, two groups of people clashed w...          0   \n",
      "1      National  On 30 May 2020, local residents staged protest...          0   \n",
      "2      National  On 30 May 2020, the local residents staged pro...          0   \n",
      "3      National  On 30 May 2020, members of Trinamool Congress ...          0   \n",
      "4      National  On 30 May 2020, local residents staged a demon...          0   \n",
      "\n",
      "    timestamp iso3  \n",
      "0  1591137952  IND  \n",
      "1  1591137952  IND  \n",
      "2  1591137952  IND  \n",
      "3  1591137952  IND  \n",
      "4  1591137952  IND  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "data_id               int64\n",
      "iso                   int64\n",
      "event_id_cnty        object\n",
      "event_id_no_cnty      int64\n",
      "event_date           object\n",
      "year                  int64\n",
      "time_precision        int64\n",
      "event_type           object\n",
      "sub_event_type       object\n",
      "actor1               object\n",
      "assoc_actor_1        object\n",
      "inter1                int64\n",
      "actor2               object\n",
      "assoc_actor_2        object\n",
      "inter2                int64\n",
      "interaction           int64\n",
      "region               object\n",
      "country              object\n",
      "admin1               object\n",
      "admin2               object\n",
      "admin3               object\n",
      "location             object\n",
      "latitude            float64\n",
      "longitude           float64\n",
      "geo_precision         int64\n",
      "source               object\n",
      "source_scale         object\n",
      "notes                object\n",
      "fatalities            int64\n",
      "timestamp             int64\n",
      "iso3                 object\n",
      "dtype: object\n",
      "0    On 30 May 2020, two groups of people clashed w...\n",
      "1    On 30 May 2020, local residents staged protest...\n",
      "2    On 30 May 2020, the local residents staged pro...\n",
      "3    On 30 May 2020, members of Trinamool Congress ...\n",
      "4    On 30 May 2020, local residents staged a demon...\n",
      "Name: notes, dtype: object\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk  # https://realpython.com/nltk-nlp-python/#chunking\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import RegexpParser\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# file_path = r'C:\\Users\\Jade Chen\\URAP_India\\conflict-india\\data\\acled_india_30may.csv'\n",
    "acled_df = pd.read_csv('acled_india_csv.csv', delimiter=';')\n",
    "\n",
    "\n",
    "# Display the first five rows and data types of each column\n",
    "print(acled_df.head(5))\n",
    "print(acled_df.dtypes)\n",
    "\n",
    "\n",
    "\n",
    "# Display the 'notes' column\n",
    "print(acled_df['notes'].head())\n",
    "\n",
    "acled_df = acled_df.head(100)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4295373e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               notes cleaned_notes\n",
      "0  On 30 May 2020, two groups of people clashed w...              \n",
      "1  On 30 May 2020, local residents staged protest...              \n",
      "2  On 30 May 2020, the local residents staged pro...              \n",
      "3  On 30 May 2020, members of Trinamool Congress ...              \n",
      "4  On 30 May 2020, local residents staged a demon...              \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define a function to prepare text for NLP\n",
    "def prep_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Tokenize the text into words\n",
    "        words = word_tokenize(text)\n",
    "\n",
    "        # Remove punctuation and convert to lowercase\n",
    "        words = [word.lower() for word in words if word.isalnum()]\n",
    "\n",
    "        # Remove stopwords using the \"english\" set of stopwords\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        words = [word for word in words if word not in stop_words]\n",
    "\n",
    "        # Lemmatizing (reduce words to their core meaning)\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "        # Stemming (reduce words to their root)\n",
    "        stemmer = PorterStemmer()\n",
    "        words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "        # Chunking (group words to identify phrases)\n",
    "        # NOTE TO SELF: change chunk grammar regexes depending on project next steps\n",
    "        grammar = r\"\"\"\n",
    "            NP: {<DT>?<JJ>*<NN>} # Chunk noun phrases\n",
    "            VP: {<VB.*><NP|PP|CLAUSE>+$} # Chunk verb phrases\n",
    "        \"\"\"\n",
    "        chunk_parser = RegexpParser(grammar)\n",
    "        tree = chunk_parser.parse(nltk.pos_tag(words))  # parses the POS-tagged words into chunks\n",
    "\n",
    "        # Chinking (excludes some pattern from chunks)\n",
    "        chink_parser = RegexpParser(\"NP: {<.*>+} # Chink all else\")\n",
    "        tree = chink_parser.parse(tree)  # Use tree.draw() to visualize tree if needed\n",
    "\n",
    "        # Convert the parsed tree back to a string\n",
    "        cleaned_text = ' '.join([word for subtree in tree for word in subtree if isinstance(word, str)])\n",
    "\n",
    "        return cleaned_text\n",
    "\n",
    "    # If text is NaN, return an empty string\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "\n",
    "# Apply the prep_text function to the 'notes' column and store in new 'cleaned_notes' column\n",
    "acled_df['cleaned_notes'] = acled_df['notes'].apply(prep_text)\n",
    "\n",
    "# Display the 'cleaned_notes' and 'notes' column\n",
    "print(acled_df[['notes', 'cleaned_notes']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc2c2a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
