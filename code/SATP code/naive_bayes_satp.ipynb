{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/christinefang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/christinefang/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction import text\n",
    "import nltk\n",
    "import re\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>internal_conflict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nagaland Post reports that a National Socialis...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On February 22, Minister of State for Home, S....</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kanglaonline reports on June 21 that a militan...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Two security personnel were seriously injured ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Union Ministry of Home Affairs (UMHA) has ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>An activist of the ruling PDP, identified as A...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>Earlier on March 3, a fire fight had occurred ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>The Kerala police recovered and later defused ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>A suspected terrorist lobbed a hand grenade at...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>Security forces continued their cordon and sea...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>510 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           description  internal_conflict\n",
       "0    Nagaland Post reports that a National Socialis...                1.0\n",
       "1    On February 22, Minister of State for Home, S....                0.0\n",
       "2    Kanglaonline reports on June 21 that a militan...                1.0\n",
       "3    Two security personnel were seriously injured ...                1.0\n",
       "4    The Union Ministry of Home Affairs (UMHA) has ...                1.0\n",
       "..                                                 ...                ...\n",
       "505  An activist of the ruling PDP, identified as A...                1.0\n",
       "506  Earlier on March 3, a fire fight had occurred ...                1.0\n",
       "507  The Kerala police recovered and later defused ...                1.0\n",
       "508  A suspected terrorist lobbed a hand grenade at...                1.0\n",
       "509  Security forces continued their cordon and sea...                1.0\n",
       "\n",
       "[510 rows x 2 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "satp = pd.read_csv('../../../sample_events.csv')\n",
    "##satp = satp[[\"description\", \"relevant_event\"]]\n",
    "satp = satp[[\"description\", \"internal_conflict\"]]\n",
    "satp = satp.drop_duplicates().reset_index(drop=True)\n",
    "satp = satp.dropna()\n",
    "satp.index = range(len(satp))\n",
    "satp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (510, 6256)\n",
      "[[0.         0.         0.         ... 0.         0.22138964 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "data_stripped = []\n",
    "data_tokenized_words = []\n",
    "\n",
    "wl = WordNetLemmatizer()\n",
    "\n",
    "for i in range(len(satp)):\n",
    "    # removes unnecessary characters\n",
    "    row = re.sub('[^a-zA-Z0-9. ]', '', satp['description'][i])\n",
    "    row = row.lower()\n",
    "    # tokenization\n",
    "    row = row.split()\n",
    "    # lemmatization and stop words removal\n",
    "    row = [wl.lemmatize(word) for word in row if not word in set(stopwords.words('english'))]\n",
    "    row2 = re.sub('[^a-zA-Z0-9 ]', '', ' '.join(row))\n",
    "    row2 = row2.split(' ')\n",
    "    row3 = ' '.join(row).split('.')\n",
    "    \n",
    "    \n",
    "    data_stripped.append(' '.join(row))\n",
    "    data_tokenized_words.append(row2)\n",
    "\n",
    "\n",
    "satp['stripped_description'] = data_stripped\n",
    "satp['word_tokenized_description'] = data_tokenized_words\n",
    "\n",
    "vectorizer = text.TfidfVectorizer(analyzer=lambda x: x)\n",
    "X = vectorizer.fit_transform(satp[\"word_tokenized_description\"])\n",
    "print(\"Shape: \",X.shape)\n",
    "print(X.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx = X[:400]\n",
    "trainy = satp['internal_conflict'][:400]\n",
    "\n",
    "validx = X[400:]\n",
    "validy = satp[\"internal_conflict\"][400:]\n",
    "validy = validy.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multinomial Naive Bayes\n",
    "nb = MultinomialNB()\n",
    "nb.fit(trainx, trainy)\n",
    "prd = nb.predict(validx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 100/110 = 0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(prd)):\n",
    "    if prd[i] == validy[i]:\n",
    "        count += 1\n",
    "print(f\"validation accuracy: {count}/{len(prd)} = {count/len(prd)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internal Conflict: validation accuracy = 90.91% (trained on 400 events, validation on 110)\n",
    "Relevant Event: validation accuracy = 68% (trained on 550 events, )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 64-bit ('.conda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "991de53ec26e165e5d99b88eaca59536b661912dfa1f1856a6e55703c4d41bc7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
