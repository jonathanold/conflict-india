{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/christinefang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/christinefang/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.feature_extraction import text\n",
    "import nltk\n",
    "import re\n",
    "import math\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>internal_conflict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nagaland Post reports that a National Socialis...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On February 22, Minister of State for Home, S....</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kanglaonline reports on June 21 that a militan...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Two security personnel were seriously injured ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>An unnamed  senior State Home department offic...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Union Ministry of Home Affairs (UMHA) has ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A woman Communist Party of India-Maoist (CPI-M...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Militants lobbed a hand grenade targeting comp...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Students under Kangleipak Students' Associatio...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>On May 5, an IED blast was reported in front o...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  internal_conflict\n",
       "0  Nagaland Post reports that a National Socialis...                1.0\n",
       "1  On February 22, Minister of State for Home, S....                0.0\n",
       "2  Kanglaonline reports on June 21 that a militan...                1.0\n",
       "3  Two security personnel were seriously injured ...                1.0\n",
       "4  An unnamed  senior State Home department offic...                0.0\n",
       "5  The Union Ministry of Home Affairs (UMHA) has ...                1.0\n",
       "6  A woman Communist Party of India-Maoist (CPI-M...                1.0\n",
       "7  Militants lobbed a hand grenade targeting comp...                1.0\n",
       "8  Students under Kangleipak Students' Associatio...                1.0\n",
       "9  On May 5, an IED blast was reported in front o...                1.0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../../sample_events.csv')\n",
    "##satp = satp[[\"description\", \"relevant_event\"]]\n",
    "df = df[[\"description\", \"internal_conflict\", \"multiple_events\", \"naxalite_maoist\"]]\n",
    "##df = df.replace()\n",
    "df = df.drop_duplicates(subset=[\"description\"]).reset_index(drop=True)\n",
    "df[\"internal_conflict\"] = df[\"internal_conflict\"].replace(r'[2-9]{1,4}', np.nan, regex=True).fillna(0)\n",
    "df.index = range(len(df))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stripped = []\n",
    "data_tokenized_words = []\n",
    "\n",
    "wl = WordNetLemmatizer()\n",
    "\n",
    "for i in range(len(df)):\n",
    "    # removes unnecessary characters\n",
    "    row = re.sub('[^a-zA-Z0-9. ]', '', df['description'][i])\n",
    "    row = row.lower()\n",
    "    # tokenization\n",
    "    row = row.split()\n",
    "    # lemmatization and stop words removal\n",
    "    row = [wl.lemmatize(word) for word in row if not word in set(stopwords.words('english'))]\n",
    "    row2 = re.sub('[^a-zA-Z0-9 ]', '', ' '.join(row))\n",
    "    row2 = row2.split(' ')\n",
    "    row3 = ' '.join(row).split('.')\n",
    "    \n",
    "    \n",
    "    data_stripped.append(' '.join(row))\n",
    "    data_tokenized_words.append(row2)\n",
    "\n",
    "\n",
    "df['stripped_description'] = data_stripped\n",
    "df['word_tokenized_description'] = data_tokenized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for cross-validation\n",
    "def cross_validation(folds, Y, accuracy_metric):\n",
    "    # Split dataset into folds\n",
    "    kf = KFold(n_splits=folds, shuffle=True)\n",
    "    accuracy = []\n",
    "    # SVM model\n",
    "    nb = MultinomialNB(force_alpha = True)\n",
    "    vectorizer = text.TfidfVectorizer(analyzer=lambda x: x,)\n",
    "    X = vectorizer.fit_transform(df[\"word_tokenized_description\"])\n",
    "\n",
    "    # Cross-validation\n",
    "    for train_idx, valid_idx in kf.split(X):\n",
    "        X_train, X_valid = X[train_idx, :], X[valid_idx, :]\n",
    "        Y_train, Y_valid = Y[train_idx], Y[valid_idx]\n",
    "        nb.fit(X_train,Y_train)\n",
    "        predictions = nb.predict(X_valid)\n",
    "        accuracy.append(accuracy_metric(predictions, Y_valid))\n",
    "    return np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracies(Y):\n",
    "        accuracy_cv = pd.DataFrame(columns = ['folds', 'validation_acc', 'balanced_acc', 'precision', 'recall'])\n",
    "\n",
    "        metrics = [accuracy_score, balanced_accuracy_score, precision_score, recall_score]\n",
    "\n",
    "        for folds in range(2,6):\n",
    "                accuracies = [folds]\n",
    "                for i in range(len(metrics)):\n",
    "                        mean_accuracy = cross_validation(folds, Y, metrics[i])\n",
    "                        accuracies.append(mean_accuracy)\n",
    "                accuracy_cv = pd.concat([pd.DataFrame([accuracies], columns=accuracy_cv.columns), accuracy_cv], ignore_index=True)\n",
    "\n",
    "        accuracy_cv['folds'] = accuracy_cv['folds'].astype('int')\n",
    "        accuracy_cv.set_index('folds')\n",
    "        return accuracy_cv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ny/vbk2t6r52hd7yvymd0bn98ww0000gp/T/ipykernel_66232/2213890824.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  accuracy_cv = pd.concat([pd.DataFrame([accuracies], columns=accuracy_cv.columns), accuracy_cv], ignore_index=True)\n",
      "/Users/christinefang/Desktop/URAP/conflict-india/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2399: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/Users/christinefang/Desktop/URAP/conflict-india/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2399: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folds</th>\n",
       "      <th>validation_acc</th>\n",
       "      <th>balanced_acc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.726410</td>\n",
       "      <td>0.692883</td>\n",
       "      <td>0.994586</td>\n",
       "      <td>0.719367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.714660</td>\n",
       "      <td>0.706680</td>\n",
       "      <td>0.992823</td>\n",
       "      <td>0.717387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.714652</td>\n",
       "      <td>0.748618</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.715370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.714660</td>\n",
       "      <td>0.732432</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.713957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   folds  validation_acc  balanced_acc  precision    recall\n",
       "0      5        0.726410      0.692883   0.994586  0.719367\n",
       "1      4        0.714660      0.706680   0.992823  0.717387\n",
       "2      3        0.714652      0.748618   1.000000  0.715370\n",
       "3      2        0.714660      0.732432   1.000000  0.713957"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies(df[\"internal_conflict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'multiple_events'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/URAP/conflict-india/.conda/lib/python3.9/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'multiple_events'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[132], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m accuracies(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmultiple_events\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[0;32m~/Desktop/URAP/conflict-india/.conda/lib/python3.9/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Desktop/URAP/conflict-india/.conda/lib/python3.9/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'multiple_events'"
     ]
    }
   ],
   "source": [
    "accuracies(df[\"multiple_events\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 115/152 = 0.756578947368421\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(prd)):\n",
    "    if prd[i] == validy[i]:\n",
    "        count += 1\n",
    "print(f\"validation accuracy: {count}/{len(prd)} = {count/len(prd)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K-fold  CV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# 10-fold CV\n",
    "scores = cross_val_score(nb, trainx, trainy, scoring = 'balanced_accuracy' , cv = 10)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internal Conflict: validation accuracy = 92.75% (trained on 500 events, validation on 110)\n",
    "\n",
    "\n",
    "Relevant Event: validation accuracy = 68%, 50%\n",
    "Balanced accuracy: 50.00%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced accuracy: = 0.4999999456521798\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(kernel, C, gamma, num_features, folds):\n",
    "    kf = KFold(n_splits=folds, shuffle=True)\n",
    "    accuracy = []\n",
    "    SVM = svm.SVC(C=C, kernel=kernel, degree=3, gamma=gamma)\n",
    "    vectorizer_tf = TfidfVectorizer(max_features=num_features)\n",
    "    encoder = LabelEncoder()\n",
    "    X = vectorizer_tf.fit_transform(cleaned_events['description']).toarray()\n",
    "    X_scaled = preprocessing.scale(X)\n",
    "    Y = encoder.fit_transform(cleaned_events['relevant_event'])\n",
    "    for train_idx, valid_idx in kf.split(X):\n",
    "        split_X_train, split_X_valid = X_scaled[train_idx, :], X_scaled[valid_idx, :]\n",
    "        split_Y_train, split_Y_valid = Y[train_idx], Y[valid_idx]\n",
    "        SVM.fit(split_X_train,split_Y_train)\n",
    "        predictions_SVM = SVM.predict(split_X_valid)\n",
    "        accuracy.append(accuracy_score(predictions_SVM, split_Y_valid))\n",
    "    return np.mean(accuracy)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.18 64-bit ('.conda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "991de53ec26e165e5d99b88eaca59536b661912dfa1f1856a6e55703c4d41bc7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
